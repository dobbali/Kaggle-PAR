---
title: "GroupProject-InterimReport"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### INTRODUCTION

  The client's requirement is a real-time effective model to predict final selling price of houses in the city of Ames, Iowa.

### OBJECTIVE

  Initial focus of the project is to gain knowledge of the data and understand the relation between each of the variables to the house's sale price. Later, further statistical analysis will be conducted to select any 5 variables which tend to effect the price the most.
  
  Later, using the training data set, a best-fitting model will be constructed with the 5 variables as predictors of housing prices. Performance of various statistical models will be compared against each other to determine which model fits the best.

### ABOUT THE DATA

  The data set available on Kaggle contains 80 variables that involve in assessing home values. Out of these, 20 are continuous, 14 are discrete and the remaining 46 are categorical variables. This data has been randomized and then split in to two sets(train and test) of equal size. "SalePrice" is the outcome variable



```{r ,include=F}
### REQUIRED PACKAGES
# install.packages("e1071")
# install.packages("Amelia")
# install.packages("RANN")
# install.packages("ipred")
# install.packages("corrplot")
# install.packages("RColorBrewer")
# install.packages("lars")
# install.packages("glmnet")
#install.packages("ggplot2")
#install.packages("devtools")
#install_github("easyGgplot2", "kassambara")

library(easyGgplot2)
library(devtools)
library(ggplot2)
library(glmnet)
library(lars)
library(RColorBrewer)
library(reshape2)
library(ggplot2)
library(e1071)
library(dplyr)
library(Amelia)
library(RANN)
library(arm)
library(caret)
library(ipred)
library(corrplot)
library(knitr)

```


```{r, include=F}
### DEFINING USEFUL FUNCTIONS
rmse <- function(y, yhat) {
  sqrt(mean((y - yhat)^2))
}

```

### DATA CLEANING AND DATA MODELLING

```{r Loading the data, include=F}

# setwd('/Users/dmatam/Google Drive/1_PC/Predictive Analytics with R/Final Project/Raw Data/')
#setwd("E:/MS/PAR/GroupProject")
setwd('/Users/mdobbali/Google Drive/University/Classes/Pred with R/Data/')


dt.train <- read.csv('train.csv', stringsAsFactors = FALSE)
dt.test <- read.csv('test.csv')
dim(dt.train)
str(dt.train)


```

Certain columns have missing values(NAs). Below is the summary of all missing value information.

```{r Summarizing information on missing values}

kable(data.frame(colSums(sapply(dt.train, is.na))))

```

```{r}

mean_sp <- mean(dt.train$SalePrice)
median_sp <- median(dt.train$SalePrice)
sd_sp <- sd(dt.train$SalePrice)

sale_price_stats <- data.frame(mean_sp, median_sp, sd_sp)
sale_price_stats

sale_price <- data.frame(dt.train$SalePrice)

hist(sale_price$dt.train.SalePrice,xlim = c(1000,800000),main = "Sale Price Distribution",xlab = 'Sale Price',freq = FALSE,col=brewer.pal(8,"Set3"),las = 3,breaks = 190)
lines(density(sale_price$dt.train.SalePrice))
max(sale_price)
#Skewed to the right

numeric_var <- names(dt.train)[which(sapply(dt.train, is.numeric))]
df.corr <- data.frame(cor(dt.train[,(numeric_var)], method="pearson"))
#View(df.corr)
typeof(df.corr)

#Correlation with Each variables and Sale Price:
df.sale.corr <- data.frame(abs(df.corr[,38]))
df.sale.corr$features <- names(df.corr)
#View(df.sale.corr)

df.sale.corr<- df.sale.corr[order(-df.sale.corr$abs.df.corr...38..),]
#View(df.sale.corr) #Ordered list of Correlations

#Top 5 correlated features
top5Corr <- df.sale.corr[2:7,]

df.corr



#Scatter Plots for Numerical 

options(scipen=5)
plot(dt.train$GrLivArea, dt.train$SalePrice, main="Scatterplot: GrLivArea vs SalePrice", 
  	xlab="Garage Liv Area ", ylab="Sales Price ", pch=20, col = "red")
abline(lm(dt.train$SalePrice~dt.train$GrLivArea), col="black") # regression line 

plot(dt.train$GarageArea, dt.train$SalePrice, main="Scatterplot: GarageArea vs SalePrice", 
  	xlab="Garage Area ", ylab="Sales Price ", pch=20, col = "red")
abline(lm(dt.train$SalePrice~dt.train$GarageArea), col="black") # regression line

plot(dt.train$TotalBsmtSF, dt.train$SalePrice, main="Scatterplot: TotalBsmtSF vs SalePrice", 
  	xlab="TotalBsmtSF ", ylab="Sales Price ", pch=20, col = "red",xlim = c(1, 3000))
abline(lm(dt.train$SalePrice~dt.train$TotalBsmtSF), col="black") # regression line

plot(dt.train$X1stFlrSF, dt.train$SalePrice, main="Scatterplot: X1stFlrSF vs SalePrice", 
  	xlab="X1stFlrSF ", ylab="Sales Price ", pch=20, col = "red",xlim = c(250, 2500))
abline(lm(dt.train$SalePrice~dt.train$X1stFlrSF), col="black") # regression line


plot(dt.train$YearBuilt, dt.train$SalePrice, main="Scatterplot: GrLivArea vs SalePrice", 
  	xlab="Year Built ", ylab="Sales Price ", pch=20, col = "red")
abline(lm(dt.train$SalePrice~dt.train$YearBuilt), col="black") # regression line 


#Categorical Varaible

p <- ggplot(dt.train, aes(factor(OverallQual), SalePrice))
p + geom_violin(scale = "width")
p + geom_violin(fill = "yellow", colour = "red")


boxplot(dt.train$SalePrice~dt.train$OverallCond, data=dt.train, notch=FALSE, 
  col=(c("gold","darkgreen")),
  main="Overall House Condition and Price", xlab="Overall Quality")

boxplot(dt.train$SalePrice~dt.train$GarageCars, data=dt.train, notch=FALSE, 
  col=(c("gold","red")),
  main="Garage Cars and Price", xlab="Overall Quality")

barplot(table(dt.train$Neighborhood),width = 0.5, main="Neighbourhood Distribution", las = 3,axisnames = TRUE, col = "Red", border = "yellow")


dt.train$bathrooms <- dt.train$FullBath + 0.5*dt.train$HalfBath
boxplot(dt.train$SalePrice~dt.train$bathrooms, data =dt.train, notch = FALSE,col=(c("gold","red")),
  main="Bathrooms and Sales price", xlab="Total Bathrooms")

```



NAs in numeric variables: Since these variables have an impact on the outcome variables, they can not be ignored. Also, the number of missing values for each variable is significantly higher which might introduce a substantial amount of bias or create reductions in efficiency. To avod this, we performed Imputation and Include methods on these variables. Imputation is a process of replacing missing data with an estimated value based on other available information.

```{r Performing Imputation on numeric variables3, include=F}

aimp <- amelia(dt.train[,which(names(dt.train) %in% c('GarageYrBlt', 'MasVnrArea', 'LotFrontage'))], m = 25)

summary(aimp)

```

```{r Performing Imputation on numeric variables1, include=T}
plot(aimp)

par(mfrow=c(1,1))

```

```{r Performing Imputation on numeric variables2, include=F}
# head(aimp$imputations[[1]])

#aimp$imputations$imp25$LotFrontage

bagImpute <- predict(preProcess(dt.train[,which(names(dt.train) %in% c('GarageYrBlt', 'MasVnrArea', 'LotFrontage'))], method = c("bagImpute")), dt.train[,which(names(dt.train) %in% c('GarageYrBlt', 'MasVnrArea', 'LotFrontage'))])
bagImpute

dt.train$GarageYrBlt <- round(bagImpute$GarageYrBlt)
dt.train$MasVnrArea <- bagImpute$MasVnrArea
dt.train$LotFrontage <- bagImpute$LotFrontage

```

NAs in character variables: All character variables contain the category of a certain feature available in the house. As per the data description from Kaggle, NAs in such cases means absence of that feature. Hence, replacing NAs with more descriptive words.

```{r Handling NAs in character variables, include=F}

dt.train$Alley <- ifelse(is.na(dt.train$Alley),"No Alley", dt.train$Alley)

dt.train$MasVnrType <- ifelse(is.na(dt.train$MasVnrType),"None", dt.train$MasVnrType)
# some data has masvnrtype none and area <> 0
#subset(dt.train, dt.train$MasVnrType == "None")$MasVnrArea 

dt.train$BsmtQual <- ifelse(is.na(dt.train$BsmtQual),"NoBsmt", dt.train$BsmtQual)

dt.train$BsmtCond <- ifelse(is.na(dt.train$BsmtCond),"NoBsmt", dt.train$BsmtCond)

dt.train$BsmtExposure <- ifelse(is.na(dt.train$BsmtExposure),"NoBsmt", dt.train$BsmtExposure)

dt.train$BsmtFinType1 <- ifelse(is.na(dt.train$BsmtFinType1),"NoBsmt", dt.train$BsmtFinType1)

dt.train$BsmtFinType2 <- ifelse(is.na(dt.train$BsmtFinType2),"NoBsmt", dt.train$BsmtFinType2)

dt.train$FireplaceQu <- ifelse(is.na(dt.train$FireplaceQu),"NoFireplace", dt.train$FireplaceQu)

dt.train$GarageType <- ifelse(is.na(dt.train$GarageType),"NoGarage", dt.train$GarageType)

dt.train$GarageFinish <- ifelse(is.na(dt.train$GarageFinish),"NoGarage", dt.train$GarageFinish)

dt.train$GarageQual <- ifelse(is.na(dt.train$GarageQual),"NoGarage", dt.train$GarageQual)

dt.train$GarageCond <- ifelse(is.na(dt.train$GarageCond),"NoGarage", dt.train$GarageCond)

dt.train$GarageCond <- ifelse(is.na(dt.train$GarageCond),"NoGarage", dt.train$GarageCond)

dt.train$PoolQC <- ifelse(is.na(dt.train$PoolQC),"NoPool", dt.train$PoolQC)

dt.train$Fence <- ifelse(is.na(dt.train$Fence),"NoFence", dt.train$Fence)

dt.train$MiscFeature <- ifelse(is.na(dt.train$MiscFeature),"NoFence", dt.train$MiscFeature)

```

Observe that all the NAs have been replaced meaningfully

```{r Calcualting number of NAs in all the variables}

kable(data.frame(colSums(sapply(dt.train, is.na))))

```


```{r inspecting multicolinearity, include=F}

df.corr <- data.frame(cor(dt.train[,(numeric_var)], method="pearson"))

df.mul.cor <- NULL 
for(i in 1:nrow(df.corr)){
  for(j in 1:i){
    df.temp <- NULL
    if(!is.na(df.corr[i,j])){
      if(df.corr[i,j] >= 0.6 && df.corr[i,j] != 1){
        df.temp$name1 <- names(df.corr)[i]
        df.temp$name2 <- names(df.corr)[j]
        df.temp$cor <- df.corr[i,j]
        df.mul.cor <- rbind(df.mul.cor,df.temp)
      }
    }
  }
}
df.mul.cor <- as.data.frame(df.mul.cor)

subset(df.mul.cor, name1 != "SalePrice")

```
The variables which have character values describe categories of multiple feautures that are desired by the buyers. Also, "OverallQual", "OverallCond", "YearBuilt", "YearRemodAdd", "TotRmsAbvGrd", "Fireplaces" have interger values which practically divide the houses based on the quantity of respective features available in the house. Hence, it makes more sense to factor these character variables as categorical

```{r Factorizing variables, include=F}

char_var <- names(dt.train)[which(sapply(dt.train, is.character))]

# allCateg_var <- c(char_var, 'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd', 'TotRmsAbvGrd', 'Fireplaces')

numeric_var <- names(dt.train)[which(sapply(dt.train, is.numeric))]
# allNumeric_var <- setdiff(numeric_var, c( 'OverallQual', 'OverallCond', 'YearBuild', 'YearRemodAdd','TotRmsAbvGrd','Fireplaces'))

for(name in char_var){
  #print(name)
  dt.train[[name]] <- factor(dt.train[[name]])
}

```

### DATA VISUALIZATION

```{r Correlation Plot, include=T}

correlations <- cor(dt.train[, numeric_var], use = "everything")
corrplot(correlations, method = "circle", type="lower",  sig.level = 0.01, insig = "blank", tl.cex=0.8, tl.col = "grey")

```

```{r Histogram of Sale Price}

sale_price <- data.frame(dt.train$SalePrice)

hist(sale_price$dt.train.SalePrice,xlim = c(1000,800000),main = "Sale Price Distribution",xlab = 'Sale Price',freq = FALSE,col=brewer.pal(8,"Set3"),las = 3,breaks = 190)
lines(density(sale_price$dt.train.SalePrice))
max(sale_price)

#Skewed to the right

#df.corr <- data.frame(cor(dt.train[,(numeric_var)], method="pearson"))
#View(df.corr)

```

### MODEL AND MODEL DEVELOPMENT

```{r, include=T,echo=F}

names(dt.train)

lm.all <- standardize(
  lm(
    SalePrice ~ MSSubClass +   MSZoning +     LotFrontage +  LotArea +      Street +       Alley +        LotShape +    
    LandContour +  Utilities +    LotConfig +    LandSlope +    Neighborhood + Condition1 +   Condition2 +   BldgType +    
    HouseStyle +   OverallQual +  OverallCond +  YearBuilt +    YearRemodAdd + RoofStyle +    RoofMatl +     Exterior1st + 
    Exterior2nd +  MasVnrType +   MasVnrArea +   ExterQual +    ExterCond +    Foundation +   BsmtQual +     BsmtCond +    
    BsmtExposure + BsmtFinType1 + BsmtFinSF1 +   BsmtFinType2 + BsmtFinSF2 +   BsmtUnfSF +    TotalBsmtSF +  Heating +     
    HeatingQC +    CentralAir +   Electrical +   X1stFlrSF +    X2ndFlrSF +    LowQualFinSF + GrLivArea +    BsmtFullBath +
    BsmtHalfBath + FullBath +     HalfBath +     BedroomAbvGr + KitchenAbvGr + KitchenQual +  TotRmsAbvGrd + Functional +  
    Fireplaces +   FireplaceQu +  GarageType +   GarageYrBlt +  GarageFinish + GarageCars +   GarageArea +   GarageQual +  
    GarageCond +   PavedDrive +   WoodDeckSF +   OpenPorchSF +  EnclosedPorch + X3SsnPorch +   ScreenPorch +  PoolArea +    
    PoolQC +       Fence +        MiscFeature +  MiscVal +      MoSold +       YrSold +       SaleType +     SaleCondition
    , data = dt.train
  )
)
```

```{r, include=T}

summary(lm.all)
# coefplot(lm.all)

coefs <-  as.data.frame(summary(lm.all)$coefficients)
coefs$vars <-  rownames(coefs)
coefs$estabs <- abs(coefs$Estimate)
coefs.20 <- coefs[order(-coefs$estabs, -coefs$`Pr(>|t|)`),][1:20,]

ggplot(coefs.20, aes(vars, Estimate)) + 
  geom_hline(yintercept=0, lty=2, lwd=1, colour="grey50") +
  geom_point(size=4, pch=21, fill="yellow") +
  theme_bw()

cat("RMSE of the baseline model with all predictors ", rmse(dt.train$SalePrice, predict(lm.all)))

```

Removing the predicts with NA as coeffiecient, because of mutli corlinearity.
Exterior2nd, BsmtCond,  BsmtFinType1, TotalBsmtSF, Electrical, GarageFinish, GarageCond, GrLivArea, GarageQual

```{r, include=T, echo=F}
lm.sel <- standardize(
  lm(
    SalePrice ~ MSSubClass +   MSZoning +     LotFrontage +  LotArea +      Street +       Alley +        LotShape +    
    LandContour +  Utilities +    LotConfig +    LandSlope +    Neighborhood + Condition1 +   Condition2 +   BldgType +    
    HouseStyle +   OverallQual +  OverallCond +  YearBuilt +    YearRemodAdd + RoofStyle +    RoofMatl +     Exterior1st + 
    # 
      MasVnrType +   MasVnrArea +   ExterQual +    ExterCond +    Foundation +   BsmtQual +    
    BsmtExposure  + BsmtFinSF1 +   BsmtFinType2 + BsmtFinSF2 +   BsmtUnfSF      +  Heating +     
    HeatingQC +    CentralAir +     X1stFlrSF +    X2ndFlrSF +    LowQualFinSF  +    BsmtFullBath +
    BsmtHalfBath + FullBath +     HalfBath +     BedroomAbvGr + KitchenAbvGr + KitchenQual +  TotRmsAbvGrd + Functional +  
    Fireplaces +   FireplaceQu +  GarageType +   GarageYrBlt +    GarageCars +   GarageArea  +  
     PavedDrive +   WoodDeckSF +   OpenPorchSF +  EnclosedPorch + X3SsnPorch +   ScreenPorch +  PoolArea +    
    PoolQC +       Fence +        MiscFeature +  MiscVal +      MoSold +       YrSold +       SaleType +     SaleCondition
    , data = dt.train
  )
)

```


```{r, include=T}

cat("RMSE of the model after removing multicollinear variables with all predictors ", rmse(dt.train$SalePrice, predict(lm.sel)))

```

Picking predictors basing on the Beta coeffiencients and P values.

```{r, include=F}

lm.df <- as.data.frame(coef(summary(lm.sel)))

names(lm.df)
lm.df$estabs <- abs(lm.df$Estimate)

```


```{r, include=T}

kable(lm.df[order(-lm.df$estabs, -lm.df$`Pr(>|t|)`),][1:20,])

```

New model with just the strong predictors.

```{r, include=T,echo=F}

lm.sel2 <- lm(SalePrice ~ RoofMatl+Condition2+PoolQC+OverallQual+RoofStyle+OverallCond+YearBuilt+GarageArea+GrLivArea+TotalBsmtSF,data=dt.train)

summary(lm.sel2)

cat("RMSE of the model with selected variables", rmse(dt.train$SalePrice, predict(lm.sel2)))  


```


```{r, include=T,echo=F}


```
